# DialogRNN Config - Fair Comparison (50 Epochs, Standardized Settings)
# ====================================================================

# CRITICAL: Architecture selection
architecture_name: dialog_rnn

# Experiment settings
experiment_name: colab_run_dialog_rnn_fair_comparison
random_seed: 42

# Data paths
data_root: /content/drive/MyDrive/dlfa_capstone/meld_data

# Model architecture settings
output_dim: 7
gru_hidden_size: 128
context_window: 10
mlp_hidden_size: 1024

# Encoder settings - FAIR COMPARISON
text_encoder_model_name: roberta-base
audio_encoder_model_name: facebook/wav2vec2-base-960h
audio_input_type: raw_wav
freeze_text_encoder: false     # UNFROZEN: for fair comparison
freeze_audio_encoder: false    # UNFROZEN: for fair comparison

# Fine-tuning settings - SIMPLIFIED FLAT STRUCTURE (2 layers for manageable params)
unfreeze_audio_layers: 2        # CONSERVATIVE: 2 layers instead of 12
unfreeze_text_layers: 2         # CONSERVATIVE: 2 layers instead of 12
audio_lr_mul: 1.5
text_lr_mul: 1.5

# Training settings - STANDARDIZED
batch_size: 8                   # Consistent across models (reduced from 16)
num_epochs: 50              
learning_rate: 2e-5             # Conservative for unfrozen encoders
weight_decay: 1e-4
optimizer_name: AdamW
gradient_clip_val: 0.5          # Conservative for stability

# Loss settings
focal_gamma: 1.0            

# Class weights for MELD emotion imbalance
class_weights: [1.62, 8.22, 11.19, 1.40, 0.45, 2.69, 2.00]

# Training options
use_mixed_precision: true
early_stopping_patience: 10  
grad_accumulation_steps: 1

# DataLoader settings
dataloader_num_workers: 2

# Additional settings
mlp_dropout_rate: 0.3

# Scheduler settings
eta_min: 1e-7 